# startDataset: int; first timestamp in the dataset
start_dataset = 1393714800000

# sts: int; offset in seconds to go ahead starting from timestamp in startDataset
# used only with Forecaster() constructor without parameter (not called from AutoScaler)
#sts = 6813480
#sts = 960000
sts = 19920

# trf: int; scale factor
# used only with Forecaster() constructor without parameter (not called from AutoScaler)
#trf = 450
trf = 20

# compressed_dataset
compressed_dataset = true

# lastTraffic
#last_traffic = 83.0,77.0,75.0,85.0,77.0,86.0,85.0,96.0,81.0,93.0
last_traffic = 274.0,389.0,496.0,940.0,1443.0,2087.0,2490.0,3741.0,3731.0,3785.0

# debug: true/false; set the debugging mode
debug = true

# worker_threshold: double; maximum and minimum %CPU of each node allowed to not scale-out/scale-in
scale-out_worker_threshold = 0.65
scale-in_worker_threshold = 0.40

# executor_threashold: double; maximum and minimum %core for each executor
scale-out_executor_threshold = 0.70
scale-in_executor_threshold = 0.20

# cluster_size: int; machine available in the cluster
cluster_size = 4

# neuralDir: String; path where ann for spout out traffic forecasting is located
# used only with Forecaster() constructor without parameter (not called from AutoScaler)
neural_dir = D:\\script\\5.encog\\Storm\\

# neuralName: String; name of neural network
neural_name = ANN-fake-ts-w=10-hStart=0-hEnd=5.eg

# update of component parallelism (if any) for runtime phase
runtime_spout0 = tweetReader,4
runtime_bolt6  = __acker,4
runtime_bolt0  = __metricsmidlab.storm.scheduler.SchedulerMetricsConsumer,1
runtime_bolt1  = counter,4
runtime_bolt2  = finalRanker,1
runtime_bolt3  = intermediateRanker,4
runtime_bolt4  = stopWordFilter,4
runtime_bolt5  = wordGenerator,4